<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.28.0/themes/prism.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.4/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@6.7.0"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.14.4"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.4/dist/index.umd.min.js"></script><script>(r => {
                setTimeout(r);
              })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{"type":"heading","depth":0,"payload":{"lines":[0,1]},"content":"知识图谱作业二","children":[{"type":"heading","depth":1,"payload":{"lines":[23,24]},"content":"一、数据处理","children":[{"type":"heading","depth":2,"payload":{"lines":[29,30]},"content":"1.1 转换地址数据","children":[{"type":"heading","depth":3,"payload":{"lines":[31,32]},"content":"遍历并打开location文件夹","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token triple-quoted-string string\">\"\"\"\n转换地址数据\n\"\"\"</span>    \npiece <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\nfiles <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>listdir<span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/location\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 得到文件夹下的所有文件名称</span>\n<span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> files<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 遍历文件夹</span>\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/location/\"</span><span class=\"token operator\">+</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 打开文件</span>\n    text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>                 <span class=\"token comment\"># 读取文件</span>\n    text <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 去除换行符</span>\n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 标签、文本长度一致</span>\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[55,56]},"content":"进行地址标签转换","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 先将所有标签置为O</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\">#</span>\n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"O\"</span>\n\n<span class=\"token comment\"># 进行标签转换</span>\nhuman_labels_index <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 人工标注的标签索引</span>\n<span class=\"token keyword\">for</span> m <span class=\"token keyword\">in</span> re<span class=\"token punctuation\">.</span>finditer<span class=\"token punctuation\">(</span><span class=\"token string\">r'\\s([^\\s]*)/LOC'</span><span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 1.匹配空格 2.匹配非空格内容 3.匹配/LOC</span>\n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"B-LOCATION\"</span> <span class=\"token comment\"># 地址开始的标签为B-LOCATION</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 地址中间的标签为I-LOCATION</span>\n        piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"I-LOCATION\"</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 人工标注的标签索引</span>\n        human_labels_index<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[74,75]},"content":"去除人工标注的地址标签","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 去除人工标注的标签</span>\npiece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 文本 -> 列表</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> human_labels_index<span class=\"token punctuation\">:</span> \n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span> <span class=\"token comment\"># 将人工标注的标签置为空格</span>\ndata<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>piece<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 添加到数据中</span>\npiece <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span> \n</code></pre>\n"}]}]},{"type":"heading","depth":2,"payload":{"lines":[88,89]},"content":"1.2 转换时间数据","children":[{"type":"heading","depth":3,"payload":{"lines":[90,91]},"content":"遍历并打开time文件夹","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\n转换时间数据\n\"\"\"</span>\nfiles <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>listdir<span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/time\"</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> files<span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 遍历文件夹</span>\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/time/\"</span><span class=\"token operator\">+</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 打开文件</span>\n            text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 读取文件</span>\n            text <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 去除换行符</span>\n            piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 标签、文本长度一致</span>\n            human_labels_index <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 人工标注的标签索引</span>\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[109,110]},"content":"进行时间标签转换","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 先将所有标签置为O</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"O\"</span>         <span class=\"token comment\"># 其他标签为O</span>\n\n<span class=\"token comment\"># 进行标签转换</span>\n<span class=\"token keyword\">for</span> m <span class=\"token keyword\">in</span> re<span class=\"token punctuation\">.</span>finditer<span class=\"token punctuation\">(</span><span class=\"token string\">r'\\s([^\\s]*)/[DT][SO]'</span><span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\">#1.匹配空格 2.匹配非空格内容 3.匹配/LOC</span>\n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"B-TIME\"</span>       <span class=\"token comment\"># 时间开始的标签为B-TIME</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"I-TIME\"</span>            <span class=\"token comment\"># 时间中间的标签为I-TIME</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        human_labels_index<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>           <span class=\"token comment\"># 人工标注的标签索引</span>\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[127,128]},"content":"去除人工标注的时间标签","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 去除人工标注的标签</span>\npiece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 文本</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> human_labels_index<span class=\"token punctuation\">:</span> <span class=\"token comment\">#</span>\n    piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span> <span class=\"token comment\"># 将人工标注的标签置为空格</span>\n\ndata<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>piece<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 添加到数据中</span>\npiece <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span> <span class=\"token comment\"># 初始化存储每一条数据的字典变量</span>\n</code></pre>\n"}]}]},{"type":"heading","depth":2,"payload":{"lines":[142,143]},"content":"1.3 保存数据","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 保存数据为json格式</span>\n<span class=\"token comment\"># json.dump(data, open(\"./data/data.json\", 'w', encoding='utf-8'), ensure_ascii=False, indent=4)</span>\n\n<span class=\"token comment\"># 保存数据为txt格式</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/data.txt\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 打开文件</span>\n    <span class=\"token keyword\">for</span> piece <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 遍历数据</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 遍历文本</span>\n            f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">\" \"</span> <span class=\"token operator\">+</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 写入文本和标签</span>\n        f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 写入换行符</span>\n\n<span class=\"token keyword\">return</span> data <span class=\"token comment\"># 返回数据</span>\n</code></pre>\n"}]}]},{"type":"heading","depth":1,"payload":{"lines":[162,163]},"content":"二. <code>BiLSTM-CRF</code>模型进行深度学习","children":[{"type":"heading","depth":2,"payload":{"lines":[164,165]},"content":"2.1 定义参数并打开数据","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\">START_TAG <span class=\"token operator\">=</span> <span class=\"token string\">\"&lt;START>\"</span>\nSTOP_TAG <span class=\"token operator\">=</span> <span class=\"token string\">\"&lt;STOP>\"</span>\nEMBEDDING_DIM <span class=\"token operator\">=</span> <span class=\"token number\">7</span> \n<span class=\"token comment\"># 由于标签一共有O， B-LOCATION, I-LOCATION， B-TIME, I-TIME，START_TAG ，STOP_TAG7个，所以embedding_dim为7</span>\nHIDDEN_DIM <span class=\"token operator\">=</span> <span class=\"token number\">4</span> <span class=\"token comment\"># 这其实是BiLSTM的隐藏层的特征数量，因为是双向所以是2倍，单向为2</span>\n\ndata <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'./data/data.json'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[185,186]},"content":"2.2 构建词典","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\">\nword_to_ix <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">for</span> piece <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> word <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> word_to_ix<span class=\"token punctuation\">:</span>\n            word_to_ix<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_to_ix<span class=\"token punctuation\">)</span>\n\ntag_to_ix <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"O\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B-LOCATION\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"I-LOCATION\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B-TIME\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"I-TIME\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> START_TAG<span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> STOP_TAG<span class=\"token punctuation\">:</span> <span class=\"token number\">6</span><span class=\"token punctuation\">}</span>\n\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[203,204]},"content":"2.3 <code>BiLSTM-CRF</code>模型","children":[{"type":"heading","depth":3,"payload":{"lines":[205,206]},"content":"关于<code>BiLSTM</code>","children":[{"type":"heading","depth":4,"payload":{"lines":[209,210]},"content":"结构"},{"type":"heading","depth":4,"payload":{"lines":[215,216]},"content":"特点","children":[{"type":"list_item","depth":5,"payload":{"lines":[219,220]},"content":"<strong>双向性</strong>：双向LSTM可以同时从前向和后向学习序列中的信息，可以更全面地捕捉序列中的上下文信息。"},{"type":"list_item","depth":5,"payload":{"lines":[220,221]},"content":"<strong>长短时记忆单元</strong>：LSTM包括<strong>门控单元</strong>，它们能够在处理序列数据时选择性地记住或遗忘先前的信息，从而能够有效地处理长期依赖关系。"},{"type":"list_item","depth":5,"payload":{"lines":[221,222]},"content":"<strong>可堆叠性</strong>：多层双向LSTM可以通过<strong>堆叠多个BiLSTM层</strong>来进一步增强模型的表达能力和学习能力。"}]}]},{"type":"heading","depth":3,"payload":{"lines":[225,226]},"content":"关于<code>BiLSTM-CRF</code>","children":[{"type":"heading","depth":4,"payload":{"lines":[229,230]},"content":"<code>BiLSTM-CRF</code>结构"},{"type":"heading","depth":4,"payload":{"lines":[235,236]},"content":"<code>BiLSTM-CRF</code>特点","children":[{"type":"list_item","depth":5,"payload":{"lines":[239,240]},"content":"双向LSTM：双向LSTM可以同时从前向和后向学习序列中的信息，可以更全面地捕捉序列中的上下文信息。"},{"type":"list_item","depth":5,"payload":{"lines":[240,241]},"content":"<code>CRF</code>层：<code>CRF</code>层可以利用序列中标签之间的依赖关系进行更准确的标注预测，从而避免独立标注每个标记时可能出现的不合理标注情况。"},{"type":"list_item","depth":5,"payload":{"lines":[241,242]},"content":"损失函数：<code>BiLSTM-CRF</code>网络使用<strong>对数似然</strong>作为损失函数，通过<strong>最大化对数似然</strong>来训练模型，从而提高模型的预测准确率。"},{"type":"list_item","depth":5,"payload":{"lines":[242,243]},"content":"预测速度：<code>BiLSTM-CRF</code>网络在预测时可以利用<strong>动态规划算法</strong>对CRF层进行高效计算，从而提高预测速度。"},{"type":"list_item","depth":5,"payload":{"lines":[243,244]},"content":"应用场景：<code>BiLSTM-CRF</code>网络广泛应用于<strong>自然语言处理任务</strong>中的序列标注问题，如<strong>命名实体识别</strong>、词性标注、语义角色标注等。"}]}]},{"type":"heading","depth":3,"payload":{"lines":[247,248]},"content":"定义和使用<code>BiLSTM-CRF</code>模型","children":[{"type":"bullet_list","depth":4,"payload":{"lines":[257,272]},"content":"","children":[{"type":"list_item","depth":5,"payload":{"lines":[257,259]},"content":"<code>BiLSTM_CRF</code>类中定义了<code>neg_log_likelihood</code>方法，<code>neg_log_likelihood</code>方法的输入是<code>sentence_in</code>和<code>targets</code>，<code>sentence_in</code>是输入的句子，<code>targets</code>是输入的标签。<br>\n<code>neg_log_likelihood</code>方法的输出是<code>loss</code>，<code>loss</code>是损失函数。"},{"type":"list_item","depth":5,"payload":{"lines":[260,262]},"content":"<code>BiLSTM_CRF</code>类中定义了<code>_get_lstm_features</code>方法，<code>_get_lstm_features</code>方法的输入是<code>sentence_in</code>，<code>sentence_in</code>是输入的句子。<br>\n<code>_get_lstm_features</code>方法的输出是<code>lstm_feats</code>，<code>lstm_feats</code>是<code>BiLSTM</code>的输出。"},{"type":"list_item","depth":5,"payload":{"lines":[263,265]},"content":"<code>BiLSTM_CRF</code>类中定义了<code>_score_sentence</code>方法，<code>_score_sentence</code>方法的输入是<code>feats</code>和<code>tags</code>，<code>feats</code>是<code>BiLSTM</code>的输出，<code>tags</code>是输入的标签。<br>\n<code>_score_sentence</code>方法的输出是<code>score</code>，<code>score</code>是<code>BiLSTM</code>的输出和标签的得分。"},{"type":"list_item","depth":5,"payload":{"lines":[266,268]},"content":"<code>BiLSTM_CRF</code>类中定义了<code>_viterbi_decode</code>方法，<code>_viterbi_decode</code>方法的输入是<code>feats</code>，<code>feats</code>是<code>BiLSTM</code>的输出。<br>\n<code>_viterbi_decode</code>方法的输出是<code>path_score</code>和<code>best_path</code>，<code>path_score</code>是最大得分，<code>best_path</code>是最大得分的路径。"},{"type":"list_item","depth":5,"payload":{"lines":[269,271]},"content":"<code>BiLSTM_CRF</code>类中定义了<code>_forward_alg</code>方法，<code>_forward_alg</code>方法的输入是<code>feats</code>，<code>feats</code>是<code>BiLSTM</code>的输出。<br>\n<code>_forward_alg</code>方法的输出是<code>alpha</code>，<code>alpha</code>是<code>BiLSTM</code>的输出的得分。"}]},{"type":"fence","depth":4,"content":"<pre class=\"language-python\"><code class=\"language-python\">\nmodel <span class=\"token operator\">=</span> BiLSTM_CRF<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_to_ix<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tag_to_ix<span class=\"token punctuation\">,</span> EMBEDDING_DIM<span class=\"token punctuation\">,</span> HIDDEN_DIM<span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> weight_decay<span class=\"token operator\">=</span><span class=\"token number\">1e-4</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span>\n\n</code></pre>\n"}]}]},{"type":"heading","depth":2,"payload":{"lines":[284,285]},"content":"2.4 训练模型","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\">\ni <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> piece <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span> <span class=\"token comment\"># 对每个句子进行训练</span>\n        sentence <span class=\"token operator\">=</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 句子</span>\n        tags <span class=\"token operator\">=</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 标签</span>\n        model<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 梯度清零</span>\n\n        <span class=\"token comment\"># 输入</span>\n        sentence_in <span class=\"token operator\">=</span> prepare_sequence<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">,</span> word_to_ix<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 将句子转化为索引</span>\n        targets <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>tag_to_ix<span class=\"token punctuation\">[</span>t<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> tags<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 将标签转化为索引</span>\n\n        <span class=\"token comment\"># 获取loss</span>\n        loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>neg_log_likelihood<span class=\"token punctuation\">(</span>sentence_in<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 计算损失</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>i<span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\tloss:\"</span><span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 打印损失</span>\n        i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span> \n        <span class=\"token comment\"># 反向传播</span>\n        loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 反向传播</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 更新参数</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[316,317]},"content":"2.5 保存模型","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 保存模型</span>\ntorch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> <span class=\"token string\">'./model.pkl'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>no_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    precheck_sent <span class=\"token operator\">=</span> prepare_sequence<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> word_to_ix<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">(</span>precheck_sent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre>\n"}]}]},{"type":"heading","depth":1,"payload":{"lines":[329,330]},"content":"三. 测试模型","children":[{"type":"heading","depth":2,"payload":{"lines":[331,332]},"content":"评价模型的查全率、查准率和F1","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 评价模型的查全率、查准率和F1</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">evaluate</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    TP <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    FP <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    FN <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> piece <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        sentence <span class=\"token operator\">=</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># 句子</span>\n        tags <span class=\"token operator\">=</span> piece<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span>   <span class=\"token comment\"># 标签</span>\n        sentence_in <span class=\"token operator\">=</span> prepare_sequence<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">,</span> word_to_ix<span class=\"token punctuation\">)</span>    <span class=\"token comment\"># 将句子转化为索引</span>\n        targets <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>tag_to_ix<span class=\"token punctuation\">[</span>t<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> tags<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 将标签转化为索引</span>\n        score<span class=\"token punctuation\">,</span> tag_seq <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>sentence_in<span class=\"token punctuation\">)</span><span class=\"token comment\"># 预测</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sentence:\"</span><span class=\"token punctuation\">,</span> sentence<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"targets:\"</span><span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tag_seq:\"</span><span class=\"token punctuation\">,</span> tag_seq<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tag_seq<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># 计算TP、FP、FN</span>\n            <span class=\"token keyword\">if</span> tag_seq<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span> <span class=\"token keyword\">or</span> tag_seq<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">2</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> tag_seq<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> targets<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                    TP <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                    FP <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> tag_seq<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> targets<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                    FN <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n    P <span class=\"token operator\">=</span> TP <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>TP <span class=\"token operator\">+</span> FP<span class=\"token punctuation\">)</span>\n    R <span class=\"token operator\">=</span> TP <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>TP <span class=\"token operator\">+</span> FN<span class=\"token punctuation\">)</span>\n    F1 <span class=\"token operator\">=</span> <span class=\"token number\">2</span> <span class=\"token operator\">*</span> P <span class=\"token operator\">*</span> R <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>P <span class=\"token operator\">+</span> R<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"P:\"</span><span class=\"token punctuation\">,</span> P<span class=\"token punctuation\">,</span> <span class=\"token string\">\"R:\"</span><span class=\"token punctuation\">,</span> R<span class=\"token punctuation\">,</span> <span class=\"token string\">\"F1:\"</span><span class=\"token punctuation\">,</span> F1<span class=\"token punctuation\">)</span>\n\nevaluate<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">)</span>\n```\n\n</code></pre>\n"}]}]}]},{})</script>
</body>
</html>
